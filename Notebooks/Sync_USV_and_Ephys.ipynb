{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9379b75a-dad2-43af-87ff-f510e19c778c",
   "metadata": {},
   "source": [
    "This notebook has code/methods for synchronizing USV recordings with ephy recordings via CS+, CS-, or the start tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c62d5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import all the functions you need\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Comment here to add in for either mac or linux computer\n",
    "if os.environ['SHELL'] == '/bin/bash':   # for linux\n",
    "    sys.path.extend(['/data/GitHub/NeuroPy']) \n",
    "    sys.path.extend(['/data/GitHub/TraceFC/'])\n",
    "else:    # For mac laptop\n",
    "    sys.path.extend(['/Users/nkinsky/Documents/UM/GitHub/NeuroPy'])\n",
    "    sys.path.extend(['/Users/nkinsky/Documents/UM/GitHub/TraceFC'])\n",
    "\n",
    "from neuropy import core\n",
    "from neuropy.io import (optitrackio,\n",
    "                        dlcio,\n",
    "                        )\n",
    "from neuropy.io.neuroscopeio import NeuroscopeIO\n",
    "from neuropy.io.binarysignalio import BinarysignalIO \n",
    "from neuropy.io.miniscopeio import MiniscopeIO\n",
    "from neuropy.core import Epoch\n",
    "from neuropy.utils import plot_util\n",
    "from neuropy.plotting.spikes import plot_raster\n",
    "from neuropy.plotting.signals import plot_signal_w_epochs\n",
    "from neuropy.plotting.spikes import plot_binned_raster\n",
    "from neuropy.io.usvio import detect_tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4a72eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for a typical recording or set of recordings\n",
    "class ProcessData:\n",
    "    def __init__(self, basepath):\n",
    "        basepath = Path(basepath)\n",
    "        self.basepath = basepath\n",
    "        xml_files = sorted(basepath.glob(\"*.xml\"))\n",
    "        assert len(xml_files) == 1, \"Found more than one .xml file\"\n",
    "        \n",
    "        fp = xml_files[0].with_suffix(\"\")\n",
    "        self.filePrefix = fp\n",
    "        \n",
    "        self.recinfo = NeuroscopeIO(xml_files[0])\n",
    "        eegfiles = sorted(basepath.glob('*.eeg'))\n",
    "        assert len(eegfiles) == 1, \"Fewer/more than one .eeg file detected\"\n",
    "        self.eegfile = BinarysignalIO(eegfiles[0], n_channels=self.recinfo.n_channels,\n",
    "                                     sampling_rate=self.recinfo.eeg_sampling_rate,\n",
    "                                     )\n",
    "        try:\n",
    "            self.datfile = BinarysignalIO(eegfiles[0].with_suffix('.dat'),\n",
    "                                         n_channels=self.recinfo.n_channels,\n",
    "                                         sampling_rate=self.recinfo.dat_sampling_rate,\n",
    "                                         )\n",
    "        except FileNotFoundError:\n",
    "            print('No dat file found, not loading')\n",
    "                \n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.recinfo.source_file.name})\"\n",
    "    \n",
    "def sess_use(basepath=os.getcwd()):\n",
    "\n",
    "    return ProcessData(basepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05ad3f9-57d4-4965-8c5a-69e302826cd9",
   "metadata": {},
   "source": [
    "## Initialize session with ephys data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "258b9191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dat file found, not loading\n",
      "filename: /Users/nkinsky/Documents/UM/Working/Trace_FC/Recording_Rats/Finn/2022_01_21_recall1/Finn_recall1_denoised.xml \n",
      "# channels: 35\n",
      "sampling rate: 30000\n",
      "lfp Srate (downsampled): 1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = Path(\"/Users/nkinsky/Documents/UM/Working/Trace_FC/Recording_Rats/Finn/2022_01_21_recall1\")\n",
    "    \n",
    "sess = sess_use(base_dir)\n",
    "print(sess.recinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80fb1e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 4002.59 seconds \n",
      "duration: 1.11 hours \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sess.eegfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c460c3-e7ab-4ad5-8a90-50c80a5b9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_tone(sorted(base_dir.glob(\"**/*.WAV\"))[0], freq_lims=(6900, 7100), tone_label=\"CS+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38876982",
   "metadata": {},
   "source": [
    "## Define probe group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4159cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core import Shank, Probe, ProbeGroup\n",
    "from neuropy.plotting import plot_probe\n",
    "shank = Shank()\n",
    "shank = shank.auto_generate(columns=1, contacts_per_column=128, xpitch=0,\n",
    "                   ypitch=20, channel_id=np.arange(128, 0, -1))\n",
    "shank.set_disconnected_channels([48, 112])\n",
    "probe = Probe(shank)\n",
    "prbgrp = ProbeGroup()\n",
    "prbgrp.add_probe(probe)\n",
    "plot_probe(prbgrp)\n",
    "prbgrp.filename = sess.filePrefix.with_suffix(\".probegroup.npy\")\n",
    "prbgrp.save(prbgrp.filename)\n",
    "sess.prbgrp = prbgrp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e11fab-f025-4643-b23d-f9c7e2862bdc",
   "metadata": {},
   "source": [
    "# Detect Theta epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95826e80-d0b0-46d1-ad9b-87a141eb65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.oscillations import detect_theta_epochs\n",
    "mindur=0.25\n",
    "maxdur=20\n",
    "thresh = (0.5, None)\n",
    "sigma = 0.125\n",
    "edge_cutoff = 0.25\n",
    "theta_channel = 55\n",
    "\n",
    "# use this if you don't know theta channel\n",
    "if theta_channel is None:\n",
    "    theta_epochs, theta_power = detect_theta_epochs(signal, prbgrp, mindur=mindur, maxdur=maxdur, thresh=thresh, \n",
    "                                                    edge_cutoff=edge_cutoff, ignore_epochs=art_epochs, return_power=True)\n",
    "else:\n",
    "    signal_use = signal.time_slice(channel_id=theta_channel)\n",
    "    theta_epochs, theta_power = detect_theta_epochs(signal_use, probegroup=None, mindur=mindur, maxdur=maxdur, thresh=thresh, \n",
    "                                                    edge_cutoff=edge_cutoff, ignore_epochs=art_epochs, return_power=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0156ad6a-a407-48a6-a571-b37236634087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.signal_process import FourierSg\n",
    "channel_use = theta_channel\n",
    "signal = sess.eegfile.get_signal()\n",
    "fsg = FourierSg(signal.time_slice(channel_id=channel_use))\n",
    "fsg_sm = FourierSg(signal.time_slice(channel_id=channel_use), sigma=2)\n",
    "fsg_mt = FourierSg(signal.time_slice(channel_id=channel_use), multitaper=True)\n",
    "fsg_mt_sm = FourierSg(signal.time_slice(channel_id=channel_use), multitaper=True, sigma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a4e9c4-beb7-413b-81ec-c4621610d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsg.freq_slice(5, 20).t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c102d-dbe5-4d5b-8291-04e1d7613a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsg_peri_cs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35c6a49-d364-420a-bdf5-d57f17f087a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(fsg_peri_cs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedbe147-d4cf-45b1-bf65-376baf88e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_sec = (5, 35)\n",
    "for fsg_use, fst_type in zip([fsg, fsg_sm, fsg\n",
    "fsg_peri_cs = []\n",
    "for start_time in cs_oe_start_df['timestamps'].values/30000:\n",
    "    ftemp = fsg_use.freq_slice(5, 12).time_slice(start_time - buffer_sec[0], start_time + buffer_sec[1])\n",
    "    fsg_peri_cs.append(ftemp.traces)\n",
    "\n",
    "_, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "sns.heatmap(fsg.freq_slice(5, 12).time_slice(1, 5000).traces, ax=ax, cmap='viridis')\n",
    "ax.invert_yaxis()\n",
    "ax.set_yticklabels([ int(freq) for freq in fsg.freq_slice(5, 12).freqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa18e9db-2682-4a6e-83c2-6c4689747bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "sns.heatmap(fsg.freq_slice(5, 12).time_slice(1, 5000).traces, ax=ax, cmap='viridis')\n",
    "ax.invert_yaxis()\n",
    "ax.set_yticklabels([ int(freq) for freq in fsg.freq_slice(5, 12).freqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e97aca-20ba-4aa5-b5e2-cf53ba4d79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.signal_process import psd_auc\n",
    "import scipy.signal as sg\n",
    "from scipy import fftpack, stats\n",
    "\n",
    "# theta_chan_signal = signal.time_slice(channel_id=[55, 56, 57, 58, 59, 60])\n",
    "# aucChans = psd_auc(signal, freq_band=(5, 12))\n",
    "\n",
    "# this calculates PSD for the WHOLE SESSION\n",
    "channel_use = 55\n",
    "window = 10\n",
    "overlap = 5\n",
    "freq_band = (5, 12)\n",
    "\n",
    "fs = signal.sampling_rate\n",
    "f, pxx = sg.welch(\n",
    "            stats.zscore(signal.time_slice(channel_id=channel_use).traces[0]),\n",
    "            fs=fs,\n",
    "            nperseg=int(window * fs),\n",
    "            noverlap=int(overlap * fs),\n",
    "            axis=-1,\n",
    "        )\n",
    "f_theta = np.where((f > freq_band[0]) & (f < freq_band[1]))[0]\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "ax.plot(f[f < 100], pxx[f < 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7d1eb-8e9c-4f46-bba8-0c3ac4c32b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try to get power in theta for whole session\n",
    "import neuropy.utils.signal_process as signal_process\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "channel_use = 55\n",
    "window = 10\n",
    "overlap = 5\n",
    "freq_band = (5, 12)\n",
    "thresh = (0.5, 2)\n",
    "sigma = 0.125\n",
    "\n",
    "signal_use = signal.time_slice(channel_id=channel_use).traces\n",
    "fs = signal.sampling_rate\n",
    "\n",
    "lf, hf = freq_band\n",
    "dt = 1 / fs\n",
    "smooth = lambda x: gaussian_filter1d(x, sigma=sigma / dt, axis=-1)\n",
    "lowthresh, highthresh = thresh\n",
    "\n",
    "# Because here one shank is selected per shank, based on visualization:\n",
    "# mean: very conservative in cases where some shanks may not have that strong ripple\n",
    "# max: works well but may have ocassional false positives\n",
    "power = np.zeros(signal_use.shape[1])\n",
    "for sig in signal_use:\n",
    "    yf = signal_process.filter_sig.bandpass(sig, lf=lf, hf=hf, fs=fs)\n",
    "    # zsc_chan = smooth(stats.zscore(np.abs(signal_process.hilbertfast(yf))))\n",
    "    # zscsignal[sig_i] = zsc_chan\n",
    "    power += np.abs(signal_process.hilbertfast(yf))\n",
    "\n",
    "# mean and smooth\n",
    "power = smooth(power / signal_use.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac13e16-8501-4e0c-8485-1aea499e4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_epochs2.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a323a-5a84-4043-a11e-798276fcc366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot these epochs for sanity checks\n",
    "%matplotlib widget\n",
    "_, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "plot_signal_w_epochs(signal, channel_use, theta_epochs2, ax=ax[0])\n",
    "ax[0].set_title('Raw Signal with theta epochs')\n",
    "theta_power_sig = signal.time_slice(channel_id=channel_use)\n",
    "theta_power_sig.traces = theta_power[None, :]\n",
    "# theta_power_sig.traces = stats.zscore(power)[None, :]\n",
    "plot_signal_w_epochs(theta_power_sig, 0, theta_epochs2, ax=ax[1])\n",
    "ax[1].set_title('Theta power signal with theta epochs')\n",
    "ax[1].axhline(thresh[0], color='r', linestyle='--')\n",
    "ax[1].axhline(thresh[1], color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1d264d-60b9-4a0e-8a3d-3f719e219f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 1\n",
    "peri_start_power = []\n",
    "peri_stop_power = []\n",
    "for start, stop in zip(theta_epochs2.starts, theta_epochs2.stops):\n",
    "    start_bool = np.bitwise_and(signal.time > (start - buffer), signal.time < (start + buffer))\n",
    "    stop_bool = np.bitwise_and(signal.time > (stop - buffer), signal.time < (stop + buffer))\n",
    "    peri_start_power.append(theta_power[start_bool])\n",
    "    peri_stop_power.append(theta_power[stop_bool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9a107-1f33-4fd4-830f-26be797af771",
   "metadata": {},
   "outputs": [],
   "source": [
    "peri_start_power2 = [start_times if len(start_times) == int(buffer*2*1250) else np.nan*np.ones(int(buffer*2*1250)) for start_times in peri_start_power]\n",
    "peri_start_power2 = np.array(peri_start_power2)\n",
    "peri_start_power2 = peri_start_power2[~np.isnan(peri_start_power2).all(axis=1)]\n",
    "peri_stop_power2 = [stop_times if len(stop_times) == int(buffer*2*1250) else np.nan*np.ones(int(buffer*2*1250)) for stop_times in peri_stop_power]\n",
    "peri_stop_power2 = np.array(peri_stop_power2)\n",
    "peri_stop_power2 = peri_stop_power2[~np.isnan(peri_stop_power2).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3635c714-19ed-4a4c-a231-47febbbf92ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks on theta power detection - looks great!\n",
    "_, ax = plt.subplots(1, 3, figsize=(8, 3), layout='tight')\n",
    "times = np.linspace(-buffer, buffer, int(fs*2*buffer))\n",
    "\n",
    "# Starts\n",
    "sns.heatmap(peri_start_power2, ax=ax[0], cbar_kws={'label': 'Theta power (z)'}, yticklabels=(len(peri_start_power2)-1),\n",
    "            xticklabels=(int(len(times)/2))-1)\n",
    "ax[0].set_xlabel('Time from theta start (s)')\n",
    "ax[0].set_xticklabels([-buffer, 0, buffer])\n",
    "ax[0].set_ylabel('Theta epoch #')\n",
    "# ax[0].\n",
    "\n",
    "# Stops\n",
    "sns.heatmap(peri_stop_power2, ax=ax[1], cbar_kws={'label': 'Theta power (z)'}, yticklabels=(len(peri_stop_power2)-1),\n",
    "            xticklabels=(int(len(times)/2))-1)\n",
    "ax[1].set_xlabel('Time from theta stop (s)')\n",
    "ax[1].set_xticklabels([-buffer, 0, buffer])\n",
    "ax[1].set_ylabel('Theta epoch #')\n",
    "\n",
    "# Means\n",
    "hstart = ax[2].plot(times, peri_start_power2.mean(axis=0), 'k-')\n",
    "hstop = ax[2].plot(times, peri_stop_power2.mean(axis=0), 'g--')\n",
    "ax[2].legend((hstart, hstop), ('Start', 'Stop'))\n",
    "ax[2].set_title('Mean theta power')\n",
    "ax[2].set_xlabel('Time from epoch start/stop (s)')\n",
    "ax[2].set_ylabel('Theta power (z)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f196cd-3206-4f30-945c-63428ee69f61",
   "metadata": {},
   "source": [
    "Ok, seems like things are working well - nice peack in theta after onset and before offset,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a0553e-dae0-481c-b898-c1b8626379f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "sns.histplot(theta_epochs.durations, bins=100, stat='probability', cumulative=False, ax=ax)\n",
    "ax.set_title('Theta epochs')\n",
    "ax.set_xlabel('Theta epoch length (s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f08bfb-a4fc-45ca-85b9-e1e894f848c7",
   "metadata": {},
   "source": [
    "# Import CS timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b6b3d-f200-4388-b17f-0ab764bee60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuropy.io.openephysio as oeio\n",
    "\n",
    "# Import TTLs for CS from OpenEphys\n",
    "ttl_df = oeio.load_all_ttl_events(sess.basepath)\n",
    "ttl_df[ttl_df['channel_states'] == 2].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed4639-7e95-420f-8f6d-1721c59dc8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracefc.io.traceio as traceio\n",
    "cs_starts, cs_ends, cs_df = traceio.load_trace_events(sess.basepath, session_type=\"tone_recall\", event_type=\"CS+\",\n",
    "                                                      return_df=True)\n",
    "print(cs_starts.shape[0])\n",
    "cs_starts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1240f191-21a5-4248-a2ae-7be0b87de164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to figure out a way to filter out/collect only the proper time stamps assuming things have a \n",
    "# +/- 1 second start difference in the CSV vs OpenEphys\n",
    "\n",
    "# Make below a function 'calc_cs_lag' in traceio module.\n",
    "start_diff = (ttl_df[ttl_df['channel_states'] == 2].head(15)['datetimes'] - cs_starts.head(15)['Timestamp'].values)\n",
    "start_diff_mean = pd.Timedelta(np.abs(start_diff.dt.total_seconds().mean()), unit='seconds')\n",
    "start_diff_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937879b-1d20-47b3-ab0c-e074153f07eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_ttl_to_openephys(trace_cs_df: pd.DataFrame, oe_ttls_df: pd.DataFrame, ttl_lag=pd.Timedelta(0.33, unit='seconds'), \n",
    "                           trace_ts_key='Timestamp', oe_ts_key='datetimes'):\n",
    "    \"\"\"Finds TTLs in OpenEphys that correspond to CS timestamps recorded from python in a CSV file, assuming a consistent\n",
    "    time lag from CS start to delivery in OpenEphys\n",
    "    ttl_lag: amount of time OE LAGS the csv in tracefc csv. Enter a negative number if lag is positive for some reason.\"\"\"\n",
    "\n",
    "    cs_bool = np.zeros(len(oe_ttls_df[oe_ts_key]), dtype=bool)\n",
    "    for event in trace_cs_df[trace_ts_key]:\n",
    "        cs_bool = cs_bool | ((oe_ttls_df[oe_ts_key] > (event - ttl_lag)) & (oe_ttls_df[oe_ts_key] < (event)))\n",
    "\n",
    "    return oe_ttls_df[cs_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d435722d-ccaa-4746-b732-98cfc3ebc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab CS times corresponding to OE timestamps\n",
    "cs_oe_start_df = trace_ttl_to_openephys(cs_starts, \n",
    "                                  ttl_df[ttl_df['channel_states'].abs() == 2], \n",
    "                                  ttl_lag=start_diff_mean*1.1)\n",
    "\n",
    "cs_oe_end_df = trace_ttl_to_openephys(cs_ends, \n",
    "                                  ttl_df[ttl_df['channel_states'].abs() == 2], \n",
    "                                  ttl_lag=start_diff_mean*1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287ef16-1bb5-4c5b-a3b0-bf299faa5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.io.openephysio import create_sync_df\n",
    "sync_df = create_sync_df(sess.basepath)\n",
    "sync_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2a624-5095-467d-b47f-6073403f74fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "\n",
    "# Next, step through each row and figure out if it matches a starts/end\n",
    "cs_oe_starts = cs_oe_start_df['timestamps']/sess.recinfo.dat_sampling_rate\n",
    "cs_oe_ends = cs_oe_end_df['timestamps']/sess.recinfo.dat_sampling_rate\n",
    "\n",
    "buffer = 5\n",
    "cs_start_power = []\n",
    "cs_stop_power = []\n",
    "for start, stop in zip(cs_oe_starts, cs_oe_ends):\n",
    "    start_bool = np.bitwise_and(signal.time > (start - buffer), signal.time < (start + buffer))\n",
    "    stop_bool = np.bitwise_and(signal.time > (stop - buffer), signal.time < (stop + buffer))\n",
    "    cs_start_power.append(theta_power[start_bool])\n",
    "    cs_stop_power.append(theta_power[stop_bool])\n",
    "\n",
    "cs_start_power = np.array(list(compress(cs_start_power, [len(start) == int(buffer*2*1250) for start in cs_start_power])))\n",
    "cs_stop_power = np.array(list(compress(cs_stop_power, [len(stop) == int(buffer*2*1250) for stop in cs_stop_power])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf53eef0-d124-47d5-8213-42989d55ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot theta power\n",
    "_, ax = plt.subplots(1, 3, figsize=(8, 3), layout='tight')\n",
    "times = np.linspace(-buffer, buffer, int(fs*2*buffer))\n",
    "\n",
    "# Starts\n",
    "sns.heatmap(cs_start_power, ax=ax[0], cbar_kws={'label': 'Theta power (z)'}, yticklabels=(len(peri_start_power2)-1),\n",
    "            xticklabels=(int(len(times)/2))-1)\n",
    "ax[0].set_xlabel('Time from CS+ start (s)')\n",
    "ax[0].set_xticklabels([-buffer, 0, buffer])\n",
    "ax[0].set_ylabel('CS+ #')\n",
    "# ax[0].\n",
    "\n",
    "# Stops\n",
    "sns.heatmap(cs_stop_power, ax=ax[1], cbar_kws={'label': 'Theta power (z)'}, yticklabels=(len(peri_stop_power2)-1),\n",
    "            xticklabels=(int(len(times)/2))-1)\n",
    "ax[1].set_xlabel('Time from CS+ stop (s)')\n",
    "ax[1].set_xticklabels([-buffer, 0, buffer])\n",
    "ax[1].set_ylabel('CS+ #')\n",
    "\n",
    "# Means\n",
    "hstart = ax[2].plot(times, cs_start_power.mean(axis=0), 'k-')\n",
    "hstop = ax[2].plot(times, cs_stop_power.mean(axis=0), 'g--')\n",
    "ax[2].legend((hstart, hstop), ('Start', 'Stop'))\n",
    "ax[2].set_title('Mean theta power')\n",
    "ax[2].set_xlabel('Time from CS+ start/stop (s)')\n",
    "ax[2].set_ylabel('Theta power (z)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08804a5-7d21-4f8d-bfda-f9d075dedc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for CS-\n",
    "csn_starts, csn_ends, csn_df = traceio.load_trace_events(sess.basepath, session_type=\"control_tone_recall\", event_type=\"CS-\",\n",
    "                                                      return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d68829b-f820-40d9-a28f-bb03ec2e650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab CS times corresponding to OE timestamps\n",
    "csn_oe_start_df = trace_ttl_to_openephys(csn_starts, \n",
    "                                  ttl_df[ttl_df['channel_states'].abs() == 2], \n",
    "                                  ttl_lag=start_diff_mean*1.1)\n",
    "\n",
    "csn_oe_end_df = trace_ttl_to_openephys(csn_ends, \n",
    "                                  ttl_df[ttl_df['channel_states'].abs() == 2], \n",
    "                                  ttl_lag=start_diff_mean*1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16123a7d-452e-46bf-9d10-8fd52fb591a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "\n",
    "# Next, step through each row and figure out if it matches a starts/end\n",
    "csn_oe_starts = csn_oe_start_df['timestamps']/sess.recinfo.dat_sampling_rate\n",
    "csn_oe_ends = csn_oe_end_df['timestamps']/sess.recinfo.dat_sampling_rate\n",
    "\n",
    "buffer = 5\n",
    "csn_start_power = []\n",
    "csn_stop_power = []\n",
    "for start, stop in zip(csn_oe_starts, csn_oe_ends):\n",
    "    start_bool = np.bitwise_and(signal.time > (start - buffer), signal.time < (start + buffer))\n",
    "    stop_bool = np.bitwise_and(signal.time > (stop - buffer), signal.time < (stop + buffer))\n",
    "    csn_start_power.append(theta_power[start_bool])\n",
    "    csn_stop_power.append(theta_power[stop_bool])\n",
    "\n",
    "csn_start_power = np.array(list(compress(csn_start_power, [len(start) == int(buffer*2*1250) for start in csn_start_power])))\n",
    "csn_stop_power = np.array(list(compress(csn_stop_power, [len(stop) == int(buffer*2*1250) for stop in csn_stop_power])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf0618-4b6e-4482-9d50-2fd7f28a19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot theta power\n",
    ", ax = plt.subplots(1, 3, figsize=(8, 3), layout='tight')\n",
    "times = np.linspace(-buffer, buffer, int(fs*2*buffer))\n",
    "\n",
    "# Starts\n",
    "sns.heatmap(csn_start_power, ax=ax[0], cbar_kws={'label': 'Theta power (z)'}, yticklabels=(len(csn_start_power)-1),\n",
    "            xticklabels=(int(len(times)/2))-1)\n",
    "ax[0].set_xlabel('Time from CS- start (s)')\n",
    "ax[0].set_xticklabels([-buffer, 0, buffer])\n",
    "ax[0].set_ylabel('CS- #')\n",
    "# ax[0].\n",
    "\n",
    "# Stops\n",
    "sns.heatmap(csn_stop_power, ax=ax[1], cbar_kws={'label': 'Theta power (z)'}, yticklabels=(len(csn_stop_power)-1),\n",
    "            xticklabels=(int(len(times)/2))-1)\n",
    "ax[1].set_xlabel('Time from CS- stop (s)')\n",
    "ax[1].set_xticklabels([-buffer, 0, buffer])\n",
    "ax[1].set_ylabel('CS- #')\n",
    "\n",
    "# Means\n",
    "hstart = ax[2].plot(times, csn_start_power.mean(axis=0), 'k-')\n",
    "hstop = ax[2].plot(times, csn_stop_power.mean(axis=0), 'g--')\n",
    "ax[2].legend((hstart, hstop), ('Start', 'Stop'))\n",
    "ax[2].set_title('Mean theta power')\n",
    "ax[2].set_xlabel('Time from CS- start/stop (s)')\n",
    "ax[2].set_ylabel('Theta power (z)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda74c6-5424-4651-b29b-193260110b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49ea220d-1fa1-4737-9665-3e6f66782f15",
   "metadata": {},
   "source": [
    "# Detect Population Burst Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f15b4b-88bc-44ab-83a0-bbf784cad6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Detect MUA.\n",
    "\n",
    "# 1a) Load in neuron spiketrains from phy\n",
    "from neuropy.io.phyio import PhyIO\n",
    "dirname = Path('/data3/Trace_FC/Recording_Rats/Django/2023_03_10_recall2/spyk-circ/Django_recall2_denoised/Django_recall2_denoised-merged.GUI')\n",
    "phy = PhyIO(dirname)\n",
    "\n",
    "# 1b) Convert spiketrains to Neurons class\n",
    "from neuropy.core.neurons import Neurons\n",
    "neurons = Neurons(phy.spiketrains, sess.eegfile.duration)\n",
    "# 1c) Convert Neurons class data to MUA class\n",
    "mua = neurons.get_mua(bin_size=0.05)\n",
    "\n",
    "# 2) Run PBE detection.\n",
    "from neuropy.analyses.spkepochs import detect_pbe_epochs\n",
    "pbe_epochs = detect_pbe_epochs(mua)\n",
    "\n",
    "# 3) Export to neuroscope\n",
    "type(pbe_epochs)\n",
    "sess.recinfo.write_epochs(pbe_epochs, ext = \"pbe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d46435-3eaf-4a7b-93aa-63a8403d8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbe_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d84f1-541b-47aa-bd23-377c31f01cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "ax.plot(mua.firing_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a20a61a-7f2d-47de-9c36-153ae1083d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname / \"spike_trains.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a3e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.pyr_neurons.spiketrains[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2481786a-28b1-4dd6-8d80-5bcb8f977818",
   "metadata": {},
   "source": [
    "# Load in neurons to Neuroscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b6f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in event timestamps\n",
    "session_type = 'tone_recall'\n",
    "\n",
    "from neuropy.io.openephysio import load_all_ttl_events, get_dat_timestamps\n",
    "events_df = load_all_ttl_events(sorted(sess.basepath.glob(f\"**/*{session_type}\"))[0])\n",
    "dat_timestamps = get_dat_timestamps(sess.basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_times_zeroed = (dat_timestamps - dat_timestamps.iloc[0])[0].dt.total_seconds().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a088f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CStimes_zeroed = [(CSon - dat_timestamps.iloc[0]).dt.total_seconds()[0] for CSon in CSon_times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4103ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5beeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbefore = 10\n",
    "tafter = 40\n",
    "CSon_tstamps = (events_df[events_df[\"channel_states\"] == 2]['datetimes'] - dat_timestamps.iloc[0])\n",
    "CSon_times = events_df[events_df[\"channel_states\"] == 2]['datetimes']\n",
    "CSon_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSTH(neurons: Neurons, neuron_id, times_zeroed, tbefore=10, tafter=40, ax=None):\n",
    "    \"\"\"Plot peri-stimulus raster\"\"\"\n",
    "    \n",
    "    # Grab appropriate neuron's spike times and pre-allocate\n",
    "    spiketimes = neurons.spiketrains[neuron]\n",
    "    ps_spike_times = []\n",
    "    \n",
    "    # Build up peri-stimulus spike times\n",
    "    for stim_start in times_zeroed:\n",
    "        trial_bool = np.bitwise_and(spiketimes > (stim_start - tbefore), spiketimes < (stim_start + tafter))\n",
    "        ps_spike_times.append(spiketimes[trial_bool] - stim_start)\n",
    "    \n",
    "    # Send to Neurons class for easy manipulation and plotting\n",
    "    rast = Neurons(ps_spike_times, t_start=-tbefore, t_stop=tafter, sampling_rate=1)\n",
    "    \n",
    "    # Plot raster\n",
    "    ax = plot_raster(rast, ax=ax)\n",
    "    \n",
    "    return rast, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb03132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CS_PSTH(neurons, neuron_id, times_zeroed, tbefore=10, tafter=40, CSdur=10, USlag=30, \n",
    "            CStype='CS+' in ['CS+', 'CS-'], training=False, ax=None):\n",
    "    \"\"\"Plots peri-stimulus time histogram for each CS with colors overlaid for CS duration\n",
    "    and US lag\"\"\"\n",
    "    \n",
    "    # Plot raster\n",
    "    rast, ax = PSTH(neurons, neuron_id, times_zeroed, tbefore=tbefore, tafter=tafter, ax=ax)\n",
    "    \n",
    "    # Add in colors for CS duration\n",
    "    assert CStype in ['CS+', 'CS-']\n",
    "    if CStype == 'CS+':\n",
    "        CScolor = [1, 0.647, 0, 0.3]\n",
    "    else:\n",
    "        CScolor = [0, 1, 0, 0.3]\n",
    "    ax.axvspan(0, CSdur, color=CScolor)\n",
    "    \n",
    "    # Add in US line\n",
    "    linetype = '-' if training else '--'\n",
    "    ax.axvline(USlag, linestyle=linetype, color='r')\n",
    "    \n",
    "    return rast, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ff3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462cce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyr_ind = np.where([ neuron in [1, 2, 3] for neuron in sess.pyr_neurons.neuron_type])[0]\n",
    "np.ceil(len(pyr_ind)/3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_sp = rast.get_binned_spiketrains(bin_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0fd9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_sp.spike_counts.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd75217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.plotting.spikes import plot_firing_rate\n",
    "rast, ax = PSTH(sess.pyr_neurons, 0, CStimes_zeroed)\n",
    "plot_firing_rate(rast, bin_size=0.5, stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 3\n",
    "\n",
    "# Pyramidal neurons\n",
    "pyr_ind = np.where([ neuron in [1, 2, 3] for neuron in sess.pyr_neurons.neuron_type])[0]\n",
    "fig, ax = plt.subplots(np.ceil(len(pyr_ind)/ncols).astype(int), ncols)\n",
    "fig.set_size_inches(10, 3*np.ceil(len(pyr_ind)/ncols).astype(int))\n",
    "fig.suptitle('Pyr neurons')\n",
    "\n",
    "for a, neuron in zip(ax.reshape(-1), pyr_ind):\n",
    "    CS_PSTH(sess.pyr_neurons, neuron, CStimes_zeroed, CStype='CS+', ax=a)\n",
    "\n",
    "# MUA\n",
    "mua_ind = np.where(sess.pyr_neurons.neuron_type == 6)[0]\n",
    "fig, ax = plt.subplots(np.ceil(len(mua_ind)/ncols).astype(int), ncols)\n",
    "fig.set_size_inches(10, 3*np.ceil(len(mua_ind)/ncols).astype(int))\n",
    "fig.suptitle('MUA')\n",
    "\n",
    "for a, neuron in zip(ax.reshape(-1), mua_ind):\n",
    "    CS_PSTH(sess.pyr_neurons, neuron, CStimes_zeroed, CStype='CS+', ax=a)\n",
    "    \n",
    "# Interneurons\n",
    "int_ind = np.where(sess.pyr_neurons.neuron_type == 8)[0]\n",
    "fig, ax = plt.subplots(np.ceil(len(int_ind)/ncols).astype(int), ncols)\n",
    "fig.set_size_inches(10, 3*np.ceil(len(int_ind)/ncols).astype(int))\n",
    "fig.suptitle('Interneurons')\n",
    "\n",
    "for a, neuron in zip(ax.reshape(-1), int_ind):\n",
    "    CS_PSTH(sess.pyr_neurons, neuron, CStimes_zeroed, CStype='CS+', ax=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8addba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.get_size_inches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e349b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.pyr_neurons.neuron_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf16e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super slow!!!\n",
    "neuron = 3\n",
    "spiketimes = sess.pyr_neurons.spiketrains[neuron]\n",
    "raster = []\n",
    "for CSon in CStimes_zeroed:\n",
    "    trial_bool = np.bitwise_and(spiketimes > (CSon - tbefore), spiketimes < (CSon + tafter))\n",
    "    raster.append(spiketimes[trial_bool] - CSon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38dd159",
   "metadata": {},
   "outputs": [],
   "source": [
    "rast1 = Neurons(raster, t_start=-tbefore, t_stop=tafter, sampling_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_raster(rast1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d0874",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df[events_df[\"channel_states\"].abs() == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c09f6e1",
   "metadata": {},
   "source": [
    "Calculate MUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04146358",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.mua = sess.pyr_neurons.get_mua(bin_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d712b9e4",
   "metadata": {},
   "source": [
    "Import curated ripple data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f72add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch\n",
    "sess.ripple = Epoch(epochs=None, file=sess.filePrefix.with_suffix('.ripple_curated.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sess.ripple.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b842b7e5",
   "metadata": {},
   "source": [
    "# Detect ripples and theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23afaeec",
   "metadata": {},
   "source": [
    "NRK - try running this with a) more aggressive artifact filter and b) selecting a better ripple channel and c) adding in a sharpwave channel too  \n",
    "  \n",
    "Also, need to run spyking-circus with median filter AND on different session - maybe less noisy/better with different preamp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9de848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch\n",
    "art_epochs = Epoch(epochs=None, file=sess.filePrefix.with_suffix('.art_epochs.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils import signal_process\n",
    "pyr_ch = 57\n",
    "sw_ch = 84\n",
    "signal = sess.eegfile.get_signal()\n",
    "yripple = signal_process.filter_sig.bandpass(signal.traces[pyr_ch], 150, 250, 1250)\n",
    "ysw = signal_process.filter_sig.bandpass(signal.traces[sw_ch], 2, 50, 1250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c23aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "zsc_ripple = stats.zscore(np.abs(signal_process.hilbertfast(yripple)))\n",
    "zsc_sw = stats.zscore(np.abs(signal_process.hilbertfast(ysw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1383027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from neuropy.analyses import oscillations\n",
    "signal = sess.eegfile.get_signal()\n",
    "# old method\n",
    "# ripple_epochs = oscillations.detect_ripple_epochs(signal, sess.prbgrp, thresh=(1, 3),\n",
    "#                                                   ignore_epochs=art_epochs, mindur=0.025)\n",
    "\n",
    "# new method\n",
    "ripple_epochs = oscillations.detect_ripple_epochs(signal, sess.prbgrp, thresh=(4, None), \n",
    "                                                  ripple_channel=pyr_ch,\n",
    "                                                  ignore_epochs=art_epochs, mindur=0.1)\n",
    "ripple_epochs.source_file = sess.filePrefix.with_suffix(\".ripple.npy\")\n",
    "sess.ripple_epochs = ripple_epochs\n",
    "sess.recinfo.write_epochs(sess.ripple_epochs, 'swr')\n",
    "sess.ripple_epochs.save(sess.filePrefix.with_suffix('.ripple.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919282d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_epochs = oscillations.detect_sharpwave_epochs(signal, sess.prbgrp, thresh=(4, None),\n",
    "                                                 edge_cutoff=1.5, ignore_epochs=art_epochs,\n",
    "                                                 sharpwave_channel=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e08d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sw_epochs.source_file = sess.filePrefix.with_suffix(\".sharpwave.npy\")\n",
    "sess.recinfo.write_epochs(sw_epochs, 'swv')\n",
    "sess.sw_epochs = sw_epochs\n",
    "sess.sw_epochs.save(sess.filePrefix.with_suffix('.ripple.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_artifact = False\n",
    "plot_sw = True\n",
    "fig, ax = plt.subplots()\n",
    "# ax.plot(np.arange(len(yripple))/1250, yripple)\n",
    "ax.plot(np.arange(len(yripple))/1250, zsc_ripple)\n",
    "ax.set_xlabel('Time (sec)')\n",
    "# ax.plot(np.arange(len(ysw))/1250, zsc_sw, '--')\n",
    "h, legend_text = [], []\n",
    "if plot_artifact:\n",
    "    for ind, epoch in art_epochs._epochs.iterrows():\n",
    "        hart = ax.axvspan(epoch['start'], epoch['stop'], color=[0, 1, 0, 0.3])\n",
    "    h.append(hart)\n",
    "    legend_text.append('Artifact')\n",
    "    \n",
    "for ind, epoch in ripple_epochs._epochs.iterrows():\n",
    "    hswr = ax.axvspan(epoch['start'], epoch['stop'], color=[1, 0, 0, 0.3])\n",
    "h.append(hswr)\n",
    "legend_text.append('Ripple')\n",
    "    \n",
    "if plot_sw:\n",
    "    for ind, epoch in sw_epochs._epochs.iterrows():\n",
    "        hswv = ax.axvspan(epoch['start'], epoch['stop'], color=[0.5, 0.5, 0, 0.3])\n",
    "    h.append(hswv)\n",
    "    legend_text.append('Sharp Wave')\n",
    "\n",
    "plt.legend(h, legend_text)\n",
    "# ax.set_xlim([2922.8, 2924.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af3751",
   "metadata": {},
   "source": [
    "### Combine epochs and get power in both bands across events and then plot and run k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b7ea7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ok, combine epochs and then get power in both bands across al\n",
    "# candidate events\n",
    "comb_epochs = pd.concat((ripple_epochs.to_dataframe(), \n",
    "                         sw_epochs.to_dataframe()))\n",
    "candidate_bool = np.zeros(sess.eegfile.n_frames, dtype=bool)\n",
    "SR = sess.eegfile.sampling_rate\n",
    "\n",
    "for idr, epoch in comb_epochs.iterrows():\n",
    "    start_frame = int(epoch['start'] * SR)\n",
    "    end_frame = int(epoch['stop'] * SR)\n",
    "    candidate_bool[start_frame:end_frame] = True\n",
    "\n",
    "candidate_bool = np.concatenate(([0], candidate_bool))\n",
    "cand_diff = np.diff(candidate_bool)\n",
    "cand_start = np.where(cand_diff == 1)[0]\n",
    "cand_end = np.where(cand_diff == -1)[0]\n",
    "epochs_array = np.vstack((cand_start, cand_end)).T.astype(int)\n",
    "cand_epochs = pd.DataFrame(\n",
    "            {\"start\": epochs_array[:, 0], \"stop\": epochs_array[:, 1], \"label\": \"\"}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb4c98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from neuropy.utils import signal_process\n",
    "import scipy.stats as stats\n",
    "pyr_ch = 24\n",
    "sw_ch = 31\n",
    "signal = sess.eegfile.get_signal()\n",
    "yripple = signal_process.filter_sig.bandpass(signal.traces[pyr_ch], 150, 250, 1250)\n",
    "ysw = signal_process.filter_sig.bandpass(signal.traces[sw_ch], 2, 50, 1250)\n",
    "zsc_ripple = stats.zscore(np.abs(signal_process.hilbertfast(yripple)))\n",
    "zsc_sw = stats.zscore(np.abs(signal_process.hilbertfast(ysw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ab974",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_power, ripple_power = [], []\n",
    "for idr, row in cand_epochs.iterrows():\n",
    "    start = row['start']\n",
    "    end = row['stop']\n",
    "    ripple_z = zsc_ripple[start:end]\n",
    "    ripple_power.append([ripple_z.mean(), ripple_z.max()])\n",
    "    \n",
    "    sw_z = zsc_sw[start:end]\n",
    "    sw_power.append([sw_z.mean(), sw_z.max()])\n",
    "\n",
    "ripple_power = np.asarray(ripple_power)\n",
    "sw_power = np.asarray(sw_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6302dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "mean_features = np.vstack((sw_power[:,0], ripple_power[:, 0])).T\n",
    "max_features = np.vstack((sw_power[:,1], ripple_power[:, 1])).T\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2264dc9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(8,3))\n",
    "n_clusters = 3\n",
    "for ida, (a, title) in enumerate(zip(ax, ['Mean', 'Max'])):\n",
    "    features = np.vstack((sw_power[:,ida], ripple_power[:, ida])).T\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(features)\n",
    "    for feat_id in np.unique(kmeans.labels_):\n",
    "        feat_bool = feat_id == kmeans.labels_\n",
    "        sns.scatterplot(x=features[feat_bool, 0], y=features[feat_bool, 1], \n",
    "                        ax=a, size=3, alpha=0.5)\n",
    "    a.set_title(title + ' Epoch Power')\n",
    "    a.set_xlabel('SW z-score')\n",
    "    a.set_ylabel('Ripple z-score')\n",
    "    a.legend([])\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dccb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext='test'\n",
    "ripple_epochs.filename.with_suffix(f\".evt.{ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c329ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NRK debug this!\n",
    "sess.ripple_epochs.epochs = sess.ripple_epochs.to_dataframe()\n",
    "NeuroscopeIO.write_epochs(sess.ripple_epochs, 'swr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18882bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_epochs.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16ac39",
   "metadata": {},
   "source": [
    "# Ok, now write code to step through each ripple event and ok it by hand - should go super fast!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf79723-a8a2-490f-ac05-4cde392cd3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c48de0-8bda-4cad-96ec-26901596aff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
